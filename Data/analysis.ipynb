{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('py37': conda)",
   "metadata": {
    "interpreter": {
     "hash": "182d1b3cf57a9fa0e072d04044576e9d27598cb3671c31bc58ed9d1764097656"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 id  conversation_id  timezone       user_id  replies_count  \\\n",
       "count  6.486600e+04     6.486600e+04   64866.0  6.486600e+04   64866.000000   \n",
       "mean   1.346076e+18     1.345947e+18    -500.0  8.438913e+17       1.159899   \n",
       "std    2.821845e+15     6.173234e+15       0.0  5.447926e+17      21.636357   \n",
       "min    1.340522e+18     3.326980e+17    -500.0  3.450300e+04       0.000000   \n",
       "25%    1.343731e+18     1.343688e+18    -500.0  3.183457e+09       0.000000   \n",
       "50%    1.346770e+18     1.346763e+18    -500.0  1.102851e+18       0.000000   \n",
       "75%    1.347417e+18     1.347374e+18    -500.0  1.290123e+18       0.000000   \n",
       "max    1.352269e+18     1.352269e+18    -500.0  1.352154e+18    1513.000000   \n",
       "\n",
       "       retweets_count   likes_count         video  near  geo  source  \\\n",
       "count    64866.000000  64866.000000  64866.000000   0.0  0.0     0.0   \n",
       "mean         2.142787      4.471356      0.441017   NaN  NaN     NaN   \n",
       "std         64.337961     45.147545      0.496513   NaN  NaN     NaN   \n",
       "min          0.000000      0.000000      0.000000   NaN  NaN     NaN   \n",
       "25%          0.000000      0.000000      0.000000   NaN  NaN     NaN   \n",
       "50%          0.000000      0.000000      0.000000   NaN  NaN     NaN   \n",
       "75%          0.000000      2.000000      1.000000   NaN  NaN     NaN   \n",
       "max       5552.000000   3242.000000      1.000000   NaN  NaN     NaN   \n",
       "\n",
       "       user_rt_id  user_rt  retweet_id  retweet_date  translate  trans_src  \\\n",
       "count         0.0      0.0         0.0           0.0        0.0        0.0   \n",
       "mean          NaN      NaN         NaN           NaN        NaN        NaN   \n",
       "std           NaN      NaN         NaN           NaN        NaN        NaN   \n",
       "min           NaN      NaN         NaN           NaN        NaN        NaN   \n",
       "25%           NaN      NaN         NaN           NaN        NaN        NaN   \n",
       "50%           NaN      NaN         NaN           NaN        NaN        NaN   \n",
       "75%           NaN      NaN         NaN           NaN        NaN        NaN   \n",
       "max           NaN      NaN         NaN           NaN        NaN        NaN   \n",
       "\n",
       "       trans_dest  \n",
       "count         0.0  \n",
       "mean          NaN  \n",
       "std           NaN  \n",
       "min           NaN  \n",
       "25%           NaN  \n",
       "50%           NaN  \n",
       "75%           NaN  \n",
       "max           NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>conversation_id</th>\n      <th>timezone</th>\n      <th>user_id</th>\n      <th>replies_count</th>\n      <th>retweets_count</th>\n      <th>likes_count</th>\n      <th>video</th>\n      <th>near</th>\n      <th>geo</th>\n      <th>source</th>\n      <th>user_rt_id</th>\n      <th>user_rt</th>\n      <th>retweet_id</th>\n      <th>retweet_date</th>\n      <th>translate</th>\n      <th>trans_src</th>\n      <th>trans_dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6.486600e+04</td>\n      <td>6.486600e+04</td>\n      <td>64866.0</td>\n      <td>6.486600e+04</td>\n      <td>64866.000000</td>\n      <td>64866.000000</td>\n      <td>64866.000000</td>\n      <td>64866.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.346076e+18</td>\n      <td>1.345947e+18</td>\n      <td>-500.0</td>\n      <td>8.438913e+17</td>\n      <td>1.159899</td>\n      <td>2.142787</td>\n      <td>4.471356</td>\n      <td>0.441017</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.821845e+15</td>\n      <td>6.173234e+15</td>\n      <td>0.0</td>\n      <td>5.447926e+17</td>\n      <td>21.636357</td>\n      <td>64.337961</td>\n      <td>45.147545</td>\n      <td>0.496513</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.340522e+18</td>\n      <td>3.326980e+17</td>\n      <td>-500.0</td>\n      <td>3.450300e+04</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.343731e+18</td>\n      <td>1.343688e+18</td>\n      <td>-500.0</td>\n      <td>3.183457e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.346770e+18</td>\n      <td>1.346763e+18</td>\n      <td>-500.0</td>\n      <td>1.102851e+18</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.347417e+18</td>\n      <td>1.347374e+18</td>\n      <td>-500.0</td>\n      <td>1.290123e+18</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.352269e+18</td>\n      <td>1.352269e+18</td>\n      <td>-500.0</td>\n      <td>1.352154e+18</td>\n      <td>1513.000000</td>\n      <td>5552.000000</td>\n      <td>3242.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('twitter_data_2020_12_20_2021_01_20.csv', parse_dates=['created_at'])\n",
    "data = data.sort_values(by='created_at')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'place': 64865}, {'quote_url': 58551}, {'thumbnail': 36259}, {'near': 64866}, {'geo': 64866}, {'source': 64866}, {'user_rt_id': 64866}, {'user_rt': 64866}, {'retweet_id': 64866}, {'retweet_date': 64866}, {'translate': 64866}, {'trans_src': 64866}, {'trans_dest': 64866}]\n"
     ]
    }
   ],
   "source": [
    "null_features_counts = list(filter(lambda x: next(iter(x.values())), \n",
    "                        map(lambda f: {f: len(data.loc[data[f].isnull()])}, data.columns)))\n",
    "print(str(null_features_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unique tweets: 48956\ntweets duplicated: 10183\ntweets duplicate rate: 0.2080031048288259\n"
     ]
    }
   ],
   "source": [
    "tweets = data.pivot_table(index=['tweet'], aggfunc ='size').to_frame()\n",
    "tweets_dups = tweets.loc[tweets[0] > 1]\n",
    "print('Unique tweets: ' + str(len(tweets.index)))\n",
    "print('tweets duplicated: ' + str(len(tweets_dups.index)))\n",
    "print('tweets duplicate rate: ' + str(len(tweets_dups.index) / len(tweets.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_retweets = data.loc[data['retweets_count'] == 0]\n",
    "duplicate_tweets = (no_retweets.groupby(['username', 'tweet']).size() \n",
    "   .sort_values(ascending=False) \n",
    "   .reset_index(name='count')\n",
    "   .drop_duplicates(subset='tweet'))\n",
    "\n",
    "duplicate_tweets = duplicate_tweets.loc[duplicate_tweets['count'] > 1]\n",
    "banned_usernames = duplicate_tweets['username']\n",
    "\n",
    "clean_data = data[~data['username'].isin(banned_usernames)]\n",
    "\n",
    "no_retweets = clean_data.loc[clean_data['retweets_count'] == 0]\n",
    "duplicate_tweets = (no_retweets.groupby(['username', 'tweet']).size() \n",
    "   .sort_values(ascending=False) \n",
    "   .reset_index(name='count')\n",
    "   .drop_duplicates(subset='tweet'))\n",
    "\n",
    "duplicate_tweets = duplicate_tweets.loc[duplicate_tweets['count'] > 1]\n",
    "banned_usernames = duplicate_tweets['username']\n",
    "\n",
    "clean_data = clean_data[~clean_data['username'].isin(banned_usernames)]\n",
    "\n",
    "# clean_data.to_csv('twitter_data_clean2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unique tweets: 25924\ntweets duplicated: 558\ntweets duplicate rate: 0.021524456102453324\n"
     ]
    }
   ],
   "source": [
    "tweets = clean_data.pivot_table(index=['tweet'], aggfunc ='size').to_frame()\n",
    "tweets_dups = tweets.loc[tweets[0] > 1]\n",
    "print('Unique tweets: ' + str(len(tweets.index)))\n",
    "print('tweets duplicated: ' + str(len(tweets_dups.index)))\n",
    "print('tweets duplicate rate: ' + str(len(tweets_dups.index) / len(tweets.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.drop_duplicates(subset='tweet', keep=\"last\")\n",
    "clean_data.to_csv('twitter_data_clean3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episode 13: ‚ö°CRYPTO THUNDERDOME‚ö° (PART 1)  Prize: $50 Amazon Gift Card üëà How: Follow &amp; Retweet üëà  (Listen to prep for 2nd‚ÅâÔ∏è prize ü§Ø)   https://t.co/K5B5n12M7B  ft. $mph $octo $meme $waves $snx $ftx $axs $sfi $zora $uma $trb #bitcoin #defi $xrp $xlm $eth $btc $rari $arte $link\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "$GRT chart going off the screen  LAMBO SOON üî•  #Bitcoin $BTC $ETH $LTC $ZEC $XRP $XLM $YFI $UNI $OMG $SUSHI $WAVES $LINK $XTZ $POLY $YFII $BCH $DASH $TRX $MAHA $AAVE $SNX $REN  https://t.co/VKIzqJhlPa\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "Live Bitcoin Trading With DeriBot on Deribit Exchange  https://t.co/d8qtEHyeuf via  @YouTube  $ZRX $ZEC $LINK $SNX $ADA $XLM $MKR $ETH $REP $LEND $XRP $DAI $WAVES $COMP $ETC $EOS $QTUM $TRX $BNB $KNC $IOTA $DCT $LTC $AMPL $OMNI\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "DeriBot Daily Trading Report 20.12.2020 11:07 UTC Bitcoin Trading Robots Comparison Report  Balance in $BTC:  0.0904 Balance in $USD:  2122.86  $ZRX $ZEC $LINK $OMNI $MKR $ETH $REP $LEND $EOS $QTUM $TRX $BNB $KNC $IOTA $DCT $LTC $AMPL $XRP $DAI $WAVES $COMP $ETC $SNX $ADA $XLM  https://t.co/fFcM1RbBwm\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "Learned about Stellar &amp; earned $XLM in return! Use my invite to join Coinbase and earn up to $50 of $XLM.  Who couldn't use free #crypto?  https://t.co/82UlbakV0l\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "$XLM Analyzed by @CryptOmeRr  https://t.co/TebPO0EiB9\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "$DATX see you at 1$  $DATX Buy back have startedüöÄ  $DATX will do X100 before listing on @coinbase next week üî•  $DATX has Partnered with @Microsoft üöÄ  $BTC $ETH $XRP $XLM $ZRD $xzc $sushi $uni $kava $rsr $meme $LINK $XTZ $BAND $ALGO $ONT $OGN $SYS $BQX $LAND $yfi $crv $neo $bch  https://t.co/oNPQ6wQyrJ\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "@RaoulGMI @Grayscale 4/ I am not going to say this is truly a case where the rich can get richer, but it certainly favors the accredited investor in a huge way.  You can repeat this with $BCH ($BCHG), $XLM, $XRP, $BTC, $ETH, etc.  Now, history tells us that the premium decreases over time as LP's..\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "@RaoulGMI @Grayscale 6/ I will take 200% on my $ETH stack any day every 6 months.  There are certain coins that do not have public vehicles yet, like $XRP and $XLM.  These may be the best early investments as your 1 year clock starts AT investment so if they go public in 6m for ex. you can be 1st out\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "Lukso. $LYXE. Do not be surprised if it reaches $10. Mainnet coming Q1 2021. This will be a game changer, FIRST OF ITS KIND. $ETH $LINK $DOT $OM $RNDR $DIA $LYXE $OCEAN $MFG $MANA $XLM $FIL $XRP $AAVE $GRT $PRQ $MAHA  https://t.co/7fz9GcP93Q\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "Any time now we will see what is called \"sleight of hands\" where $btc will start to make its first correction since all time high. During this correction the altcoins will run fast and hard and btc dominance will drop like a rock. $ZAP $XRP $XLM $ICX $LINK\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "Its a great platform with so many functions!   #Stellarfamily #Socialbanking #B2B #B2C #Stellar $CLIX $XLM #XLM #Bitcoin #cryptocurrencies\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "Just learned about Stellar and earned $XLM in return! Use my invite to join Coinbase and earn up to $50 of $XLM.  https://t.co/gcN9o8OeRH\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "#xlm $xlm #bitcoin üî•üî•üî•  #stellar destek b√∂lgesinde cebelle≈üiyor  https://t.co/HU1YnW2o5E\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "Verox presale is live! üî•  Welcome to the best investment currently in crypto!   Innovating #Crypto with #AIüèÖ Audited codeüíØ  Only 50k supplyüíé 1 $ETH = 60 $VRX üöÄ  üëâ https://t.co/IeZguhnjSN  $btc $nano $maha $tri $defo $xlm $zil $ddim $grt $doge $xrp $ltc $link $dot $akro $prq  https://t.co/Q2a28aYzAr\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "[sic]  Needs to be seen.   $OCEAN turned from hype beast to currently most underpriced crypto w/ institutional ties &amp; tier 1 partners out there.   üéÑ-discount, here you go üåäüíÅ‚Äç‚ôÇÔ∏è: ‚Äî‚Äî‚Äî  CC: $FET $AGI $EWT $NEO $NANO $GRT $ADA $XLM $XRP $BCH $LTC $QNT\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è  The recent @Ledger leak / hack a few months ago should lead people to ask this question right now:  How well are our passport copies protected at @Binance @Coinbase @Kraken ‚Ä¶ ?  #cryptocurrency $btc $eth $xrp $bch $link $ltc $ada $bnb $dot $xlm $eos #bitcoin   ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "$JUV and $PSG will be listing on #Binance 12/21 6:00 UTC (10 hours left), First billion dollar football clubs on Binance with 1.3m Circulating tokens each. Which one will rocket harder? Take your pick.   $btc $eth $xlm $xrp $grt $chz $link\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "If you're not balls deep in $KAI then its about time you should be. DO NOT miss this opportunity üöÄüöÄüöÄüöÄ $kai $vite $cos $top $eth $ocean $dot $ksm $icx $trx $lto $vet $xlm $pcx $wtc $omg $theta $defi #bullish #crypto $link $neo $band $Ankr $OM $ogn $mitx $matic  $fleta #Bitcoin\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "Which crypto will see the most gains by EOY??  Apple Music Link:  https://t.co/B3cEDPpaxe  $eth $xrp $link $ltc $bnb $eos $xtz $xlm $vet #rapmusic $doge #blockchain $rep $band #grt #altcoin #bitcoin #BITCOINMEG #cryptotrading $grt #thegraph #Dogecoin #DeFi\n",
      "Empty DataFrame\n",
      "Columns: [id, tweet]\n",
      "Index: []\n",
      "*NEW* Video posted for $BTC #Bitcoin Live members \"Cryptocurrency Market Update - Dec 20th 2020\"  $BTC $LTC $ETH $BCH $ADA $BAT $BNB $EOS $LINK $ONT $TRX $XLM $XMR $XRP $XTZ $YFI  Why should you join? Watch my webinar here -&gt;  https://t.co/aDfgdmEiUj   https://t.co/tHeDMvR5Vj\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "nothing to repeat at position 0",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-13c54a47a93d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mfiltered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mid_tweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mid_tweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mid\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mid_tweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1999\u001b[0m                 )\n\u001b[0;32m   2000\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2001\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2003\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36mcontains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m   2822\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mforbid_nonstring_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bytes\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2823\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2824\u001b[1;33m         result = str_contains(\n\u001b[0m\u001b[0;32m   2825\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2826\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36mstr_contains\u001b[1;34m(arr, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[0mregex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;34m\"Compile a regular expression pattern, returning a Pattern object.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m         \u001b[1;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[0;32m    444\u001b[0m                            not nested and not items))\n\u001b[0;32m    445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    666\u001b[0m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mAT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m                 raise source.error(\"nothing to repeat\",\n\u001b[0m\u001b[0;32m    669\u001b[0m                                    source.tell() - here + len(this))\n\u001b[0;32m    670\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_REPEATCODES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: nothing to repeat at position 0"
     ]
    }
   ],
   "source": []
  }
 ]
}